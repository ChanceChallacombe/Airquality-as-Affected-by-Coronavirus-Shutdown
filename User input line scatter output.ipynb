{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what kind of graph do you want to plot? line or scatter?scatter\n",
      "What Location? k\n"
     ]
    }
   ],
   "source": [
    "# all data files were downloaded from the airnow archive\n",
    "# Import the libraries\n",
    "import numpy as np\n",
    "import random\n",
    "import pprint\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import (MultipleLocator, FormatStrFormatter,\n",
    "                               AutoMinorLocator)\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "# a function that when the data path to the data file and the location/city are inputted in the parameter\n",
    "# returns a dictionary with the units and types of measure as keys corresponding with their respective measurements\n",
    "# as well as a list of the keys, the values, and the measure so later a loop can iterate through the dictionary and \n",
    "#conditionals can be met. The data from the start file is added. \n",
    "#Caution in order for the program to work as intended proceed from start date onwards\n",
    "def create_dictionary(data_path, location):\n",
    "    #initializing the list that holds the type of measure, ex Ozone 8hr this will be returned by the function\n",
    "    measure=[]\n",
    "    #initializing the list that holds the units for the measure, ex PPB\n",
    "    unit=[]\n",
    "    #initializing the list that holds the actual numerical numbers, ex 48 this will be returned by the function\n",
    "    measurement=[]\n",
    "    #initializing the local dictionary that is going to be returned by the function\n",
    "    dictionary={}\n",
    "    #initializing the list that will hold the dictionary keys that will be returned by the function\n",
    "    legend=[]\n",
    "    #open the data file from the data path parameter inputted in the function \n",
    "    with open(data_path, encoding='latin-1') as f:\n",
    "        #iterating through each line in the data file splitting by the delimiter '|'\n",
    "        for line in f:\n",
    "            line = line.split('|')\n",
    "            if (line[2]==str(location)):\n",
    "                #add the respective data to the list that describes it\n",
    "                measure.append(line[3])\n",
    "                unit.append(line[4])\n",
    "                measurement.append(line[5])\n",
    "    #iterate through the length of the data\n",
    "    for i in range (0,len(measure)):\n",
    "        #make the keys for the dictionary out of the measure and the units, ex Ozone-8hr in PPB\n",
    "        key=(str(measure[i])+' in '+str(unit[i]))\n",
    "        #adding the keys to the legen list\n",
    "        legend.append(key)\n",
    "        val=measurement[i]\n",
    "        #float is used since some dat is decimal\n",
    "        dictionary[key]=[float(val)]\n",
    "    return dictionary, legend, measurement, measure\n",
    "\n",
    "\n",
    "#a function that takes the parameters of the dat file the location/city, the legend, the measure and the dictionary the data will be added to\n",
    "#adds the data to the dictionary created above in the same list connected to the right keys\n",
    "def add_data(data_path,location,dictionary):\n",
    "    with open(data_path, encoding='latin-1') as f:\n",
    "        #the flags for missing data if the flag is false 'no Data' will be appended to the list\n",
    "        if 'CO-8hr in PPM' not in dictionary.keys():\n",
    "            dictionary['CO-8hr in PPM'] = ['NoData']\n",
    "        if 'OZONE-1HR in PPB' not in dictionary.keys():\n",
    "            dictionary['OZONE-1HR in PPB'] = ['NoData']\n",
    "        if 'OZONE-8HR in PPB' not in dictionary.keys():\n",
    "            dictionary['OZONE-8HR in PPB'] = ['NoData']\n",
    "        if 'PM10-24hr in UG/M3' not in dictionary.keys():\n",
    "            dictionary['PM10-24hr in UG/M3'] = ['NoData']\n",
    "        if 'PM2.5-24hr in UG/M3' not in dictionary.keys():\n",
    "            dictionary['PM2.5-24hr in UG/M3'] = ['NoData'] \n",
    "        if 'SO2-24HR in PPB' not in dictionary.keys():\n",
    "            dictionary['SO2-24HR in PPB'] = ['NoData']\n",
    "        CO8hr=False\n",
    "        OZONE1HR=False\n",
    "        OZONE8HR=False\n",
    "        PM1024hr=False\n",
    "        PM2524hr=False\n",
    "        SO224HR=False\n",
    "        #itereating through the data file and splitting by the delimiter '|'\n",
    "        for line in f:\n",
    "            line = line.split('|')\n",
    "            #making sure the right data was captured\n",
    "            if (line[2]==str(location)):\n",
    "                #making the flags true if the data is present and adding the data to the correct key\n",
    "                if(line[3]=='CO-8hr'):\n",
    "                    CO8hr=True\n",
    "                    dictionary['CO-8hr in PPM'].append(line[5])\n",
    "                elif(line[3]=='OZONE-1HR'):\n",
    "                    OZONE1HR=True\n",
    "                    dictionary['OZONE-1HR in PPB'].append(line[5])\n",
    "                elif(line[3]=='OZONE-8HR'):\n",
    "                    OZONE8HR=True\n",
    "                    dictionary['OZONE-8HR in PPB'].append(line[5])\n",
    "                elif(line[3]=='PM10-24hr'):\n",
    "                    PM1024hr=True\n",
    "                    dictionary['PM10-24hr in UG/M3'].append(line[5])\n",
    "                elif(line[3]=='PM2.5-24hr'):\n",
    "                    PM2524hr=True\n",
    "                    dictionary['PM2.5-24hr in UG/M3'].append(line[5])\n",
    "                elif(line[3]=='SO2-24HR'):\n",
    "                    SO224HR=True\n",
    "                    dictionary['SO2-24HR in PPB'].append(line[5])\n",
    "         #if the flags are false add a placeholder to the data               \n",
    "        if (CO8hr==False):\n",
    "            dictionary['CO-8hr in PPM'].append('NoData')\n",
    "        elif (OZONE1HR==False):\n",
    "            dictionary['OZONE-1HR in PPB'].append('NoData')\n",
    "        elif (OZONE8HR==False):\n",
    "            dictionary['OZONE-8HR in PPB'].append('NoData')\n",
    "        elif (PM1024hr==False):\n",
    "            dictionary['PM10-24hr in UG/M3'].append('NoData')\n",
    "        elif (PM2524hr==False):\n",
    "            dictionary['PM2.5-24hr in UG/M3'].append('NoData')\n",
    "        elif (SO224HR==False):\n",
    "            dictionary['SO2-24HR in PPB'].append('NoData') \n",
    "\n",
    "            \n",
    "#a function that removes the placeholder 'NoData' generates a xlist for plotting and removes \n",
    "#the corresponding indices as the placeholder\n",
    "def check_missing_data(dictionary_key):\n",
    "    #generate the xlist for plotting\n",
    "    xlist=np.arange(1, (len(dictionary_key)+1), 1).tolist()\n",
    "    #the ylist is the same as the dictionary data\n",
    "    ylist=dictionary_key\n",
    "    #initialize the local index list that stores the indexes of the 'NoData'\n",
    "    index=[]\n",
    "    for i in range (0,len(dictionary_key)):\n",
    "        if (ylist[i]=='NoData'):\n",
    "            #store the nodata indexes\n",
    "            index.append(i)\n",
    "    #remove the 'NoData' values and their corresponding x time value\n",
    "    for i in sorted(index, reverse=True):\n",
    "        del xlist[i]\n",
    "        del ylist[i]\n",
    "    #return the x and y list for plotting\n",
    "    return xlist,ylist\n",
    "\n",
    "\n",
    "\n",
    "#plot a line graph of the city over three years for a specific measure/key\n",
    "def line_plotter(dictionary2020,dictionary2019,dictionary2018,dictionary_key):\n",
    "    fig, ax1=plt.subplots(nrows=1, ncols=1, figsize=(30,10))\n",
    "    ax1.plot(check_missing_data(dictionary2020[dictionary_key])[0],check_missing_data(dictionary2020[dictionary_key])[1],c='green')\n",
    "    ax1.plot(check_missing_data(dictionary2019[dictionary_key])[0],check_missing_data(dictionary2019[dictionary_key])[1],c='blue')\n",
    "    ax1.plot(check_missing_data(dictionary2018[dictionary_key])[0],check_missing_data(dictionary2018[dictionary_key])[1],c='purple')\n",
    "    ax1.set_xlabel('Days After March 1')\n",
    "    ax1.set_ylabel(dictionary_key)\n",
    "    ax1.legend(['2020','2019','2018'],loc='upper left')\n",
    "    ax1.xaxis.set_major_locator(MultipleLocator(7))\n",
    "    ax1.xaxis.set_minor_locator(MultipleLocator(1))\n",
    "    ax1.set_title('line graph from March 1 to April 30 of air quality in:\\n'+dictionary_key+' of:\\n'+city+'\\n')\n",
    "    \n",
    "\n",
    "#a function which handed a list of uni variate data finds the mean of that data\n",
    "def mean(data):\n",
    "    # makes sure that if there is no data in the list zero is returned instead of the mean\n",
    "    if (len(data)!=0):\n",
    "        sumOfData = 0.0\n",
    "        for i in range(0,len(data)):\n",
    "            sumOfData+=data[i]\n",
    "        return sumOfData/(len(data))\n",
    "    else:\n",
    "        return 0\n",
    "#a function which finds the standard deviation of data in a list inputted as the parameter data\n",
    "def stDev (data):\n",
    "    sumOfDifference = 0.0\n",
    "    for i in range(0,len(data)):\n",
    "        sumOfDifference+=((data[i]-mean(data))*(data[i]-mean(data)))\n",
    "    return (math.sqrt(sumOfDifference/len(data)))\n",
    "\n",
    "#a function that finds the corelation coefficient r for bivariate data inputted as two lists into \n",
    "# their respective parameters of explanatory and response\n",
    "def correlation(explanatory,response):\n",
    "    sumOfDifferences=0.0\n",
    "    for i in range(0,len(explanatory)):\n",
    "        if (len(explanatory)==len(response)):\n",
    "            sumOfDifferences+=((explanatory[i]-mean(explanatory))*(response[i]-mean(response)))\n",
    "    return (sumOfDifferences/(stDev(explanatory)*stDev(response)))/(len(explanatory))\n",
    "\n",
    "#a function that finds the least squares regression line variables for bivariate data \n",
    "#inputed in the explanatory and response parameters of the function\n",
    "def leastSquares(explanatory,response):\n",
    "    r=round(correlation(explanatory,response),3)\n",
    "    m=round(r*stDev(response)/stDev(explanatory),3)\n",
    "    b=round(mean(response)-m*mean(explanatory),3)\n",
    "    return m,b,r\n",
    "\n",
    "#a function which takes a dictionary and a dictionary key then plots a scatter plot and least squares line\n",
    "#of the data with respect to time, the residual plot of the scatterplot and a histogram of the residuals\n",
    "#the function also accesses the correlation, prints the assessment, the equation of the line, and the \n",
    "#correlation coefficient r\n",
    "def scatter_LSq_Resid_Hist(dictionary, dictionary_key):\n",
    "    #get rit of the missing data in the dictionary and replace the integer value with floating point values\n",
    "    #this is done so that division through the list by a float is possible\n",
    "    # set an x and ylist for the data\n",
    "    x=[float(i) for i in check_missing_data(dictionary[dictionary_key])[0]]\n",
    "    ylist=[float(i) for i in check_missing_data(dictionary[dictionary_key])[1]]\n",
    "    #initialize a residual list\n",
    "    resid=[]\n",
    "    # make sure that there is at least some data in the dictionary if there is not mean will return 0\n",
    "    if (mean(x)!=0 and mean(ylist)!=0):\n",
    "        fig, (ax1,ax2,ax3)=plt.subplots(nrows=1, ncols=3, figsize=(18.75,5))\n",
    "        #get the m,x, and r values for the least squares regression\n",
    "        m,b,r=leastSquares(x,ylist)\n",
    "        #access the correlation\n",
    "        #note these values are by no means set and were only created according to my interpretation of strength\n",
    "        if (abs(r)>0.75):\n",
    "            corel='The correlation is strong'\n",
    "        elif (abs(r)>0.60):\n",
    "            corel='The correlation is fairly strong'\n",
    "        elif (abs(r)>0.50):\n",
    "            corel='The correlation is fairly weak'\n",
    "        elif (abs(r)>0.40):\n",
    "            corel='The correlation is very weak'\n",
    "        elif (r!=0):\n",
    "            corel='The correlation is almost non-existence'\n",
    "        else:\n",
    "            corel='There is no correlation'\n",
    "        #initialize and compute the y values for the least squares regression line inorder to plot it\n",
    "        y=[(i*m)+b for i in x]\n",
    "        #add the residuals to the residual list actual-predicted where ylist is the actual values and y is the\n",
    "        #predicted\n",
    "        for i in range(0,len(ylist)):\n",
    "            resid.append(ylist[i]-y[i])\n",
    "        #plot the scatterplot and least square line\n",
    "        ax1.scatter(x=check_missing_data(dictionary[dictionary_key])[0],y=check_missing_data(dictionary[dictionary_key])[1],s=200,marker='.',c='black',edgecolor='g')\n",
    "        ax1.plot(x,y)\n",
    "        ax1.legend([('y='+ str(m)+'x'+'+'+str(b))],loc='upper left')\n",
    "        ax1.set_xlabel('Days After First State Stay at Home Order: March 19')\n",
    "        ax1.set_ylabel(dictionary_key)\n",
    "        ax1.xaxis.set_major_locator(MultipleLocator(7))\n",
    "        ax1.xaxis.set_minor_locator(MultipleLocator(1))\n",
    "        ax1.set_title('Least square regression line formula to three decimal places is:\\n'+'y='+ \\\n",
    "        str(m)+'x'+'+'+str(b)+'\\n'+'correlation coefficient r is:\\n'+str(r)+'\\n'+str(corel))\n",
    "        #plot the residual plot\n",
    "        ax2.scatter(x=check_missing_data(dictionary[dictionary_key])[0],y=resid,s=200,marker='.',c='black',edgecolor='r')\n",
    "        ax2.xaxis.set_major_locator(MultipleLocator(7))\n",
    "        ax2.xaxis.set_minor_locator(MultipleLocator(1))\n",
    "        ax2.set_title('Residual plot\\n Linear regression is a good fit if there is no clear pattern')\n",
    "        ax2.axhline(linewidth=1, color='black')\n",
    "        #plot histogram\n",
    "        ax3.hist(resid, bins = 10)\n",
    "        ax3.set_title('Distribution for residuals\\n The more symmetric and closer to normal the better\\n Note the bin size may not be appropriate for all data')\n",
    "    else:\n",
    "        fig, ax1=plt.subplots(nrows=1, ncols=1, figsize=(5,5))\n",
    "        ax1.scatter(x=check_missing_data(dictionary[dictionary_key])[0],y=check_missing_data(dictionary[dictionary_key])[1],marker='.',c='black',edgecolor='g')\n",
    "        ax1.legend(['y=0x+0'],loc='upper left')\n",
    "        ax1.set_xlabel('Days After First State Stay at Home Order: March 19')\n",
    "        ax1.set_ylabel(dictionary_key)\n",
    "        ax1.xaxis.set_major_locator(MultipleLocator(7))\n",
    "        ax1.xaxis.set_minor_locator(MultipleLocator(1))\n",
    "        ax1.set_title('All Data is Zero\\nLeast square regression line formula to three decimal places is:\\ny=0x+0\\ncorrelation is not applicable')\n",
    "\n",
    "#a function which prints a list of locations from an airnow dat file\n",
    "def location_list(data_path):\n",
    "    with open(data_path, encoding='latin-1') as f:\n",
    "        duplicate_list=[]\n",
    "        location_list=[]\n",
    "        for line in f:\n",
    "            line = line.split('|')\n",
    "            duplicate_list.append(line[2])\n",
    "        for i in duplicate_list:\n",
    "                if i not in location_list:\n",
    "                    location_list.append(i)\n",
    "    return location_list\n",
    "def sample(dictionary1,dictionary2):\n",
    "    x=0\n",
    "#determine which type of graph to use based on user input\n",
    "type_of_graph=input('what kind of graph do you want to plot? line or scatter?')\n",
    "print ('Choose a location from the list and enter it below the list')\n",
    "print (location_list('/home/usr/airnowDat/2020/20200319-peak.dat'))\n",
    "print ('Choose a location from the list')\n",
    "#determine which city/location to pull data from based on user input \n",
    "city=input('What Location? ')\n",
    "#if scatter was chosen grab data from after march 19 and create and add that data to a dictionary\n",
    "#March 19th was the first stay at home state order so I wanted to see by scatter and regression if airquality increased\n",
    "# or air quality increased after CoVID shutdown so did people and businnesses restart driving etc \n",
    "#after an initial decrease\n",
    "if (type_of_graph=='scatter'):\n",
    "    #create a city 2018 dictionary with respective measure,values and legend\n",
    "    city_2018,city_legend_2018,city_values_2018,city_measure_2018=create_dictionary('/home/usr/airnowDat/2018/20180319-peak.dat',city)\n",
    "    #Add the rest of the 2018 data to the city 2018 dictionary\n",
    "    for i in range(20,32):\n",
    "        add_data(('/home/usr/airnowDat/2018/201803'+str(i)+'-peak.dat'),city,city_2018)\n",
    "    for i in range(1,10):\n",
    "        add_data(('/home/usr/airnowDat/2018/2018040'+str(i)+'-peak.dat'),city,city_2018)\n",
    "    for i in range(10,31):\n",
    "        add_data(('/home/usr/airnowDat/2018/201804'+str(i)+'-peak.dat'),city,city_2018)\n",
    "\n",
    "    #create a city 2019 dictionary with respective measure,values and legend\n",
    "    city_2019,city_legend_2019,city_values_2019,city_measure_2019=create_dictionary('/home/usr/airnowDat/2019/20190319-peak.dat',city)\n",
    "    #Add the rest of the 2019 data to the city 2019 dictionary\n",
    "    for i in range(20,32):\n",
    "        add_data(('/home/usr/airnowDat/2019/201903'+str(i)+'-peak.dat'),city,city_2019)\n",
    "    for i in range(1,10):\n",
    "        add_data(('/home/usr/airnowDat/2019/2019040'+str(i)+'-peak.dat'),city,city_2019)\n",
    "    for i in range(10,31):\n",
    "        add_data(('/home/usr/airnowDat/2019/201904'+str(i)+'-peak.dat'),city,city_2019)\n",
    "\n",
    "    #create a city 2020 dictionary with respective measure,values and legend\n",
    "    city_2020,city_legend_2020,city_values_2020,city_measure_2020=create_dictionary('/home/usr/airnowDat/2020/20200319-peak.dat',city)\n",
    "    #Add the rest of the 2020 data to the city 2020 dictionary\n",
    "    for i in range(20,32):\n",
    "        add_data(('/home/usr/airnowDat/2020/202003'+str(i)+'-peak.dat'),city,city_2020)\n",
    "    for i in range(1,10):\n",
    "        add_data(('/home/usr/airnowDat/2020/2020040'+str(i)+'-peak.dat'),city,city_2020)\n",
    "    for i in range(10,31):\n",
    "        add_data(('/home/usr/airnowDat/2020/202004'+str(i)+'-peak.dat'),city,city_2020)\n",
    "    #plot the data as a scatterplot, linear regression line, residual plot and histogram\n",
    "    #for all measures in the legend of the dictionary\n",
    "    for i in range (0,len(city_legend_2020)):\n",
    "        scatter_LSq_Resid_Hist(city_2020,city_legend_2020[i])\n",
    "\n",
    "#If line was chosen graph data from March and April to see if airparticulates decreased sharply at any \n",
    "#point due to COVID shutdown comparing to 2019 and 2018 as control        \n",
    "elif (type_of_graph=='line'):\n",
    "    #create a city 2018 dictionary with respective measure,values and legend\n",
    "    city_2018,city_legend_2018,city_values_2018,city_measure_2018=create_dictionary('/home/usr/airnowDat/2018/20180319-peak.dat',city)\n",
    "    #Add the rest of the 2018 data to the city 2018 dictionary\n",
    "    for i in range(1,10):\n",
    "        add_data(('/home/usr/airnowDat/2018/2018030'+str(i)+'-peak.dat'),city,city_2018)\n",
    "    for i in range(10,32):\n",
    "        add_data(('/home/usr/airnowDat/2018/201803'+str(i)+'-peak.dat'),city,city_2018)\n",
    "    for i in range(1,10):\n",
    "        add_data(('/home/usr/airnowDat/2018/2018040'+str(i)+'-peak.dat'),city,city_2018)\n",
    "    for i in range(10,31):\n",
    "        add_data(('/home/usr/airnowDat/2018/201804'+str(i)+'-peak.dat'),city,city_2018)\n",
    "\n",
    "    #create a city 2019 dictionary with respective measure,values and legend\n",
    "    city_2019,city_legend_2019,city_values_2019,city_measure_2019=create_dictionary('/home/usr/airnowDat/2019/20190319-peak.dat',city)\n",
    "    #Add the rest of the 2019 data to the city 2019 dictionary\n",
    "    for i in range(1,10):\n",
    "        add_data(('/home/usr/airnowDat/2019/2019030'+str(i)+'-peak.dat'),city,city_2019)\n",
    "    for i in range(20,32):\n",
    "        add_data(('/home/usr/airnowDat/2019/201903'+str(i)+'-peak.dat'),city,city_2019)\n",
    "    for i in range(1,10):\n",
    "        add_data(('/home/usr/airnowDat/2019/2019040'+str(i)+'-peak.dat'),city,city_2019)\n",
    "    for i in range(10,31):\n",
    "        add_data(('/home/usr/airnowDat/2019/201904'+str(i)+'-peak.dat'),city,city_2019)\n",
    "\n",
    "    #create a city 2020 dictionary with respective measure,values and legend\n",
    "    city_2020,city_legend_2020,city_values_2020,city_measure_2020=create_dictionary('/home/usr/airnowDat/2020/20200319-peak.dat',city)\n",
    "    #Add the rest of the 2020 data to the city 2020 dictionary\n",
    "    for i in range(1,10):\n",
    "        add_data(('/home/usr/airnowDat/2020/2020030'+str(i)+'-peak.dat'),city,city_2020)\n",
    "    for i in range(20,32):\n",
    "        add_data(('/home/usr/airnowDat/2020/202003'+str(i)+'-peak.dat'),city,city_2020)\n",
    "    for i in range(1,10):\n",
    "        add_data(('/home/usr/airnowDat/2020/2020040'+str(i)+'-peak.dat'),city,city_2020)\n",
    "    for i in range(10,31):\n",
    "        add_data(('/home/usr/airnowDat/2020/202004'+str(i)+'-peak.dat'),city,city_2020)\n",
    "    #plot the data as a line graph for all measures in the legend of the dictionary\n",
    "    for i in range (0,len(city_legend_2020)):\n",
    "        line_plotter(city_2020,city_2019,city_2018,city_legend_2020[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
